{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29724,
     "status": "ok",
     "timestamp": 1555933331958,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "EY1DWQaIwpGx",
    "outputId": "882ed22f-d2b7-4770-a228-0d6b4ceb0ddf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29706,
     "status": "ok",
     "timestamp": 1555933331967,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "eBsHkzz4wvB3",
    "outputId": "80a715c2-2cd8-497c-a950-5ed63a793641"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30412,
     "status": "ok",
     "timestamp": 1555933332695,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "ARcVP5_uwx7O",
    "outputId": "df0d5501-befc-495e-ecf9-a6f531194062"
   },
   "outputs": [],
   "source": [
    "%cd dmsoroki-gym_interf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39928,
     "status": "ok",
     "timestamp": 1555933342225,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "xcdnpzdiw2Pd",
    "outputId": "3751ac98-cc34-46cf-ce69-4728f5ef9835"
   },
   "outputs": [],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27015,
     "status": "ok",
     "timestamp": 1555933351935,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "DGr9tRmM-Jf6",
    "outputId": "74cc704b-1e7e-40c5-b5bb-5d59a3a34b38"
   },
   "outputs": [],
   "source": [
    "!pip install gym==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzozJqGXya0_"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_interf\n",
    "\n",
    "env = gym.make('interf-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27563,
     "status": "ok",
     "timestamp": 1555933355682,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "TReuIobwB1y2",
    "outputId": "710d987e-da3e-42af-b31d-c5b791cee8e0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display    \n",
    "print(\"Is python : {}\".format(is_ipython))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device : {}\".format(device))\n",
    "\n",
    "\n",
    "ACTIONS_NUM = 8\n",
    "print(\"Number of actions : {}\".format(ACTIONS_NUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B855txz_CF9O"
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self, capacity = 40000):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTf-oaazCM4G"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, in_channels=16, num_actions=ACTIONS_NUM):\n",
    "        \n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.conv4 = nn.Conv2d(64,1024,kernel_size=4,stride=1)\n",
    "        self.advantage = nn.Linear(512, num_actions)\n",
    "        self.value = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        advantage,value = torch.split(x,512,dim=1)\n",
    "        \n",
    "        advantage = advantage.view(advantage.shape[0],-1)\n",
    "        value = value.view(value.shape[0],-1)\n",
    "        \n",
    "        advantage = self.advantage(advantage)\n",
    "        value = self.value(value)\n",
    "        q_value = value.expand(value.shape[0],ACTIONS_NUM) +\\\n",
    "        advantage-torch.mean(advantage,dim=1).unsqueeze(1).expand(advantage.shape[0],ACTIONS_NUM)\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnjzA1aJCzd3"
   },
   "outputs": [],
   "source": [
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer =optim.Adam(policy_net.parameters(),lr=1e-5)\n",
    "\n",
    "memory = ReplayMemory()\n",
    "\n",
    "def select_action(state, eps_threshold):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            state=state.float()\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(ACTIONS_NUM)]], device=device, dtype=torch.long)\n",
    "\n",
    "train_rewards = []\n",
    "\n",
    "mean_size = 100\n",
    "mean_step = 1\n",
    "\n",
    "def plot_rewards(rewards = train_rewards, name = \"Train\"):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(rewards)\n",
    "    if len(rewards) > mean_size:\n",
    "        means = np.array([rewards[i:i+mean_size:] for i in range(0, len(rewards) - mean_size, mean_step)]).mean(1)\n",
    "        means = np.concatenate((np.zeros(mean_size - 1), means))\n",
    "        plt.plot(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8wr_6TvC4JP"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    \n",
    "    \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    \n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    \n",
    "    state_batch=state_batch.float()\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    \n",
    "    non_final_next_states=non_final_next_states.float()\n",
    "    next_state_values = torch.zeros((BATCH_SIZE,1), device=device)\n",
    "    next_state_actions = torch.zeros(BATCH_SIZE,dtype=torch.long, device=device)\n",
    "    \n",
    "    next_state_actions[non_final_mask] = policy_net(non_final_next_states).max(1)[1]\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1, next_state_actions[non_final_mask].unsqueeze(1))\n",
    "    next_state_values=next_state_values.squeeze(1)\n",
    "    \n",
    "    \n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1).detach())\n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    del non_final_mask\n",
    "    del non_final_next_states\n",
    "    del state_batch\n",
    "    del action_batch\n",
    "    del reward_batch\n",
    "    del state_action_values\n",
    "    del next_state_values\n",
    "    del expected_state_action_values\n",
    "    del loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GK6tpBmXHeQd"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "  TEST_EPS = 0.005\n",
    "  state = env.reset() \n",
    "  total_reward = 0\n",
    "  for i in count():\n",
    "    state = np.array(state,dtype=np.float32)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "    state = state.unsqueeze(0)\n",
    "    action = select_action(state, TEST_EPS)\n",
    "    state, _, done, info = env.step(action)\n",
    "    reward = -1.0+info['visib']\n",
    "    total_reward+=reward\n",
    "    if done:\n",
    "       break\n",
    "  return i+1,total_reward,info['visib']\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4631716,
     "status": "error",
     "timestamp": 1555945203798,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "Bs3QbaD-C8vH",
    "outputId": "7bc9fcab-0de7-41b6-e359-6f32ea2527da"
   },
   "outputs": [],
   "source": [
    "NUM_EPISODES = 200000\n",
    "\n",
    "\n",
    "OPTIMIZE_MODEL_STEP = 4\n",
    "\n",
    "\n",
    "TARGET_UPDATE=10000\n",
    "\n",
    "\n",
    "\n",
    "STEPS_BEFORE_TRAIN = 30000\n",
    "\n",
    "\n",
    "\n",
    "EPS_START = 1\n",
    "EPS_END = 0.1\n",
    "EPS_DECAY = 1000000\n",
    "\n",
    "EPS_START_v2 = 0.1\n",
    "EPS_END_v2 = 0.01\n",
    "\n",
    "policy_net.train()\n",
    "target_net.eval()\n",
    "test_rewards = []\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "for e in range(NUM_EPISODES):\n",
    "\n",
    "    state = env.reset() \n",
    "    state = np.array(state,dtype=np.float32)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "    state = state.unsqueeze(0)\n",
    "    ep_rewards=0\n",
    "    \n",
    "    for t in range(180000):\n",
    "\n",
    "        \n",
    "        if steps_done<EPS_DECAY:\n",
    "            if steps_done>STEPS_BEFORE_TRAIN:\n",
    "                fraction=min(float(steps_done)/EPS_DECAY,1)\n",
    "                eps_threshold= EPS_START + (EPS_END - EPS_START) * fraction\n",
    "                action = select_action(state,eps_threshold)\n",
    "            else:\n",
    "                action=torch.tensor([[random.randrange(ACTIONS_NUM)]], device=device, dtype=torch.long)\n",
    "        \n",
    "        else:\n",
    "            fraction=min(float(steps_done)/2*EPS_DECAY,1)\n",
    "            eps_threshold= EPS_START_v2 + (EPS_END_v2 - EPS_START_v2) * fraction\n",
    "            action = select_action(state,eps_threshold)\n",
    "            \n",
    "            \n",
    "        \n",
    "        next_state, _, done,info = env.step(action.item())\n",
    "        reward = -1.0+info['visib']\n",
    "        ep_rewards += reward\n",
    "        \n",
    "        next_state = np.array(next_state,dtype=np.float32)\n",
    "        next_state = torch.tensor(next_state,dtype=torch.float32,device=device)\n",
    "        next_state = next_state.unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        if not done:\n",
    "            memory.push(state, action,next_state, reward)\n",
    "        else:\n",
    "            next_state=None\n",
    "            memory.push(state, action,next_state, reward)  \n",
    "              \n",
    "        steps_done+=1\n",
    "        state=next_state\n",
    "       \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        if (steps_done > STEPS_BEFORE_TRAIN) and steps_done % OPTIMIZE_MODEL_STEP == 0:\n",
    "            optimize_model()\n",
    "        \n",
    "\n",
    "        if steps_done % TARGET_UPDATE == 0:\n",
    "            print(\"Target net updated!\")\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "\n",
    "        if done:\n",
    "            train_rewards.append(np.sum(ep_rewards))         \n",
    "            plot_rewards()\n",
    "            break \n",
    "    if e%100==0:\n",
    "      policy_net.eval()\n",
    "      total = 0\n",
    "      val = 0 \n",
    "      visib_end = 0.\n",
    "      for _ in range(10):\n",
    "        res0,res1,final_visib = test()\n",
    "        val+= res0\n",
    "        total += res1\n",
    "        visib_end+=final_visib\n",
    "      policy_net.train()\n",
    "      print('---- steps_done {}  ---- Test_score {} ----- Number of steps needed {} --- final_visib = {}'.format(steps_done,total/10.,val/10.,visib_end/10.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tShTxj6coes0"
   },
   "outputs": [],
   "source": [
    "torch.save(policy_net.state_dict(),'policy_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yK8HaznFABO_"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-mLi2jhcrNZ"
   },
   "outputs": [],
   "source": [
    "# TEST_EPS = 0.005\n",
    " \n",
    "dist_all = []\n",
    "action_all = []\n",
    "visib_all = []\n",
    "steps = []\n",
    "TEST_EPS = 0.0\n",
    "env.reset_actions = 1000\n",
    "env.max_steps = 200\n",
    "for _ in range(100):\n",
    "  state = env.reset()\n",
    "  total_reward = 0\n",
    "  for i in count():\n",
    "    state = np.array(state,dtype=np.float32)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "    state = state.unsqueeze(0)\n",
    "    action = select_action(state, TEST_EPS)\n",
    "    state, _, done, info = env.step(action)\n",
    "    reward = -1.0+info['visib']\n",
    "    total_reward+=reward\n",
    "    # dist_all.append(info['dist'])\n",
    "    # visib_all.append(info['visib'])\n",
    "    # action_all.append(action)\n",
    "    if done:\n",
    "        steps.append(i)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1696,
     "status": "ok",
     "timestamp": 1555948463407,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "C5eFRpXOqGBS",
    "outputId": "323952e9-c67a-4108-ef1a-7d2f1dfdac36"
   },
   "outputs": [],
   "source": [
    "steps = np.array(steps)\n",
    "steps[steps<100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1555948467156,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "LLcCUMKqrr8d",
    "outputId": "57785c06-90f5-4936-8a5e-a7b23ea6ae6d"
   },
   "outputs": [],
   "source": [
    "np.sort(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FO47zPAvuJOp"
   },
   "outputs": [],
   "source": [
    "steps = []\n",
    "dist_all = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2gUnJMLtjuE"
   },
   "outputs": [],
   "source": [
    "# TEST_EPS = 0.005\n",
    " \n",
    "action_all = []\n",
    "visib_all = []\n",
    "TEST_EPS = 0.0\n",
    "env.reset_actions = 5000\n",
    "env.max_steps = 200\n",
    "state = env.reset()\n",
    "total_reward = 0\n",
    "for i in count():\n",
    "  state = np.array(state,dtype=np.float32)\n",
    "  state = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "  state = state.unsqueeze(0)\n",
    "  action = select_action(state, TEST_EPS)\n",
    "  state, _, done, info = env.step(action)\n",
    "  reward = -1.0+info['visib']\n",
    "  total_reward+=reward\n",
    "  if i == 0:\n",
    "    dist_all.append(info['dist'])\n",
    "  visib_all.append(info['visib'])\n",
    "  action_all.append(action)\n",
    "  if done:\n",
    "    \n",
    "    steps.append(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1681,
     "status": "ok",
     "timestamp": 1555948347048,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "iTO99bq3uEpy",
    "outputId": "dd1c9ee0-629f-41e6-f1e9-c79bc2eb6da8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(steps,dist_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1555947879000,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "OMqYprvFk_zr",
    "outputId": "615714f9-4c20-4dea-ecdd-92ba7c6695bc"
   },
   "outputs": [],
   "source": [
    "plt.plot(dist_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1555947860068,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "hyjcRNPYlMA5",
    "outputId": "1d38a14c-bdce-4f65-8464-759ad083be95"
   },
   "outputs": [],
   "source": [
    "plt.plot(visib_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1555946366620,
     "user": {
      "displayName": "Арсен Ринатович Кужамуратов",
      "photoUrl": "",
      "userId": "11945829493768460540"
     },
     "user_tz": -180
    },
    "id": "91F-GXFWlUBL",
    "outputId": "853d4833-b39c-40c0-9b04-8edaa9f5e52c"
   },
   "outputs": [],
   "source": [
    "visib_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcbFbW9alqjJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "interfer1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
